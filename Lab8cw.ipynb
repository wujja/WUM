{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treść zadania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel: klasyfikacja recenzji jako pozytywnej lub negatywnej, porownac 3 modele, trenowane z walidacją:\n",
    "# model.fit(xtrain, ytrain, epochs = epochs, batch_size = bsize, validation_split=0.4)\n",
    "# modele:\n",
    "# 1 zwykla mala siec 16,16,1\n",
    "# 2 taka sama siec, ale z regularyzacją np. L2, np.:\n",
    "# layers.Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\")\n",
    "# 3 taka jak w 1 ale z dropout (dodaje się za kazda zwykla warstwą ukrytą warstwe dodtkową), np.:\n",
    "# layers.Dropout(0.5)\n",
    "# dane: imdb (mozna sciagnac z keras.datasets imdb.load_data(num_words = ...))\n",
    "# UWAGA: dla kazdego modelu nalezy:\n",
    "# a) wykonac wykres miary jakosci treningowej i walidacyjnej podczas epok uczenia\n",
    "# ad a): wykresy nalezy wykonac przyrostowo (tzn. zeby na koncu porownac wszystkie modele)\n",
    "# b) dla kazdego modelu dokonac ewaluacji na zbiorze testowym\n",
    "# na koniec wytrenowac najlepszy model dla optymalnej liczby epok i osiagnac jak najlepsza miare na testowym\n",
    "\n",
    "# dodatkowe zadania:\n",
    "# porownac model (np. za pomoca wykresow metryki podczas uczenia) trenowany na zwyklych danych i\n",
    "# I\n",
    "# a) wytrenowany na danych z dodanymi atrybutami zerowymi\n",
    "# b) wytrenowany na danych z dodanymi atrybutami losowymi\n",
    "# (czy oba uszkodzenia danych szkodzą? które bardziej i dlaczego?)\n",
    "# II\n",
    "# a) trenowany na sieci takiej jak wczesniej\n",
    "# b) trenowany na sieci o mniejszych mozliwosciach (mniej neuronow)\n",
    "# c) trenowany na sieci o wiekszych mozliwosciach (wiecej neuronow)\n",
    "# czy sa roznice w historii trenowania? jakie? jaki ma to wplyw na przetrenowanie?\n",
    "# III porownac rozne wartosci zmiennej uczacej (learning rate): zwykla, za mala, za duza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytywanie zbioru \n",
    "nwords = 5000\n",
    "nseed = 10000\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = nwords, seed=nseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zakodowanie danych jako bag of words\n",
    "def vectorize(data, dimension = nwords):\n",
    "    result = np.zeros((len(data), dimension))\n",
    "    for i, l in enumerate(data):\n",
    "        for w in l:\n",
    "            result [i, w] = 1.\n",
    "    return result\n",
    "\n",
    "x_train = vectorize(train_data)\n",
    "x_test = vectorize(test_data) \n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "bsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8273 - val_loss: 0.3105 - val_accuracy: 0.8760\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.9091 - val_loss: 0.3772 - val_accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1971 - accuracy: 0.9262 - val_loss: 0.3148 - val_accuracy: 0.8752\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1690 - accuracy: 0.9363 - val_loss: 0.3259 - val_accuracy: 0.8793\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1479 - accuracy: 0.9463 - val_loss: 0.3503 - val_accuracy: 0.8748\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1326 - accuracy: 0.9513 - val_loss: 0.3922 - val_accuracy: 0.8645\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9609 - val_loss: 0.4130 - val_accuracy: 0.8650\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1025 - accuracy: 0.9633 - val_loss: 0.4554 - val_accuracy: 0.8646\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0873 - accuracy: 0.9707 - val_loss: 0.4914 - val_accuracy: 0.8606\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0729 - accuracy: 0.9772 - val_loss: 0.6439 - val_accuracy: 0.8490\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0604 - accuracy: 0.9822 - val_loss: 0.5786 - val_accuracy: 0.8583\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 0.6381 - val_accuracy: 0.8589\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.7224 - val_accuracy: 0.8507\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.7718 - val_accuracy: 0.8542\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.8470 - val_accuracy: 0.8535\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.9651 - val_accuracy: 0.8522\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 1.0670 - val_accuracy: 0.8539\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 1.1529 - val_accuracy: 0.8535\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.2332 - val_accuracy: 0.8527\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.3285 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a861eaef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation = \"relu\"),\n",
    "    layers.Dense(16, activation = \"relu\"),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "\n",
    "model.fit(x_train, train_labels, epochs = epochs, batch_size = bsize, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.4813 - accuracy: 0.8308 - val_loss: 0.3969 - val_accuracy: 0.8666\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3273 - accuracy: 0.9020 - val_loss: 0.3734 - val_accuracy: 0.8787\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2951 - accuracy: 0.9142 - val_loss: 0.3927 - val_accuracy: 0.8725\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2790 - accuracy: 0.9229 - val_loss: 0.3885 - val_accuracy: 0.8748\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2669 - accuracy: 0.9261 - val_loss: 0.3864 - val_accuracy: 0.8764\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2603 - accuracy: 0.9280 - val_loss: 0.4209 - val_accuracy: 0.8631\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2516 - accuracy: 0.9313 - val_loss: 0.3945 - val_accuracy: 0.8712\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2457 - accuracy: 0.9347 - val_loss: 0.4078 - val_accuracy: 0.8669\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2390 - accuracy: 0.9337 - val_loss: 0.4005 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9378 - val_loss: 0.4264 - val_accuracy: 0.8615\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9384 - val_loss: 0.4059 - val_accuracy: 0.8677\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9423 - val_loss: 0.4166 - val_accuracy: 0.8675\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9426 - val_loss: 0.4120 - val_accuracy: 0.8684\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9472 - val_loss: 0.4212 - val_accuracy: 0.8629\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9483 - val_loss: 0.4447 - val_accuracy: 0.8597\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9495 - val_loss: 0.4411 - val_accuracy: 0.8624\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9531 - val_loss: 0.4633 - val_accuracy: 0.8569\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1843 - accuracy: 0.9582 - val_loss: 0.4551 - val_accuracy: 0.8558\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1768 - accuracy: 0.9593 - val_loss: 0.4498 - val_accuracy: 0.8582\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1710 - accuracy: 0.9631 - val_loss: 0.4461 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a81da7490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.002),activation = \"relu\"),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.002),activation = \"relu\"),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "\n",
    "model.fit(x_train, train_labels, epochs = epochs, batch_size = bsize, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.5824 - accuracy: 0.6914 - val_loss: 0.4056 - val_accuracy: 0.8579\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8294 - val_loss: 0.3094 - val_accuracy: 0.8791\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.8771 - val_loss: 0.2925 - val_accuracy: 0.8844\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2875 - accuracy: 0.8989 - val_loss: 0.2946 - val_accuracy: 0.8849\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2612 - accuracy: 0.9107 - val_loss: 0.3061 - val_accuracy: 0.8861\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2376 - accuracy: 0.9209 - val_loss: 0.3257 - val_accuracy: 0.8867\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.3380 - val_accuracy: 0.8833\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9290 - val_loss: 0.3550 - val_accuracy: 0.8821\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.9292 - val_loss: 0.3717 - val_accuracy: 0.8823\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1920 - accuracy: 0.9321 - val_loss: 0.3951 - val_accuracy: 0.8798\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.9357 - val_loss: 0.4096 - val_accuracy: 0.8789\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9366 - val_loss: 0.4290 - val_accuracy: 0.8763\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1831 - accuracy: 0.9333 - val_loss: 0.4354 - val_accuracy: 0.8760\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1719 - accuracy: 0.9383 - val_loss: 0.4494 - val_accuracy: 0.8748\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9419 - val_loss: 0.4740 - val_accuracy: 0.8746\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1682 - accuracy: 0.9404 - val_loss: 0.4760 - val_accuracy: 0.8732\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1692 - accuracy: 0.9395 - val_loss: 0.4987 - val_accuracy: 0.8725\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1543 - accuracy: 0.9433 - val_loss: 0.5163 - val_accuracy: 0.8734\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9402 - val_loss: 0.5115 - val_accuracy: 0.8730\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9407 - val_loss: 0.5072 - val_accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a86513040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation = \"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation = \"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "\n",
    "model.fit(x_train, train_labels, epochs = epochs, batch_size = bsize, validation_split=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('PAD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9f784632b142558421957d14033287e602729fbcb5ff7dd2a51001edb95a0e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
